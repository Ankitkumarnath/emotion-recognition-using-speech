{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df8a89-2aeb-4fb7-b5c7-a8097fed4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing dataset...\n",
      "Found 4224 audio files\n",
      "Emotions: {'sad', 'neutral', 'angry', 'disgust', 'fear', 'pleasant_surprise', 'happy'}\n",
      "Processing file 1/4224\n",
      "Processing file 51/4224\n",
      "Processing file 101/4224\n",
      "Processing file 151/4224\n",
      "Processing file 201/4224\n",
      "Processing file 251/4224\n",
      "Processing file 301/4224\n",
      "Processing file 351/4224\n",
      "Processing file 401/4224\n",
      "Processing file 451/4224\n",
      "Processing file 501/4224\n",
      "Processing file 551/4224\n",
      "Processing file 601/4224\n",
      "Processing file 651/4224\n",
      "Processing file 701/4224\n",
      "Processing file 751/4224\n",
      "Processing file 801/4224\n",
      "Processing file 851/4224\n",
      "Processing file 901/4224\n",
      "Processing file 951/4224\n",
      "Processing file 1001/4224\n",
      "Processing file 1051/4224\n",
      "Processing file 1101/4224\n",
      "Processing file 1151/4224\n",
      "Processing file 1201/4224\n",
      "Processing file 1251/4224\n",
      "Processing file 1301/4224\n",
      "Processing file 1351/4224\n",
      "Processing file 1401/4224\n",
      "Processing file 1451/4224\n",
      "Processing file 1501/4224\n",
      "Processing file 1551/4224\n",
      "Processing file 1601/4224\n",
      "Processing file 1651/4224\n",
      "Processing file 1701/4224\n",
      "Processing file 1751/4224\n",
      "Processing file 1801/4224\n",
      "Processing file 1851/4224\n",
      "Processing file 1901/4224\n",
      "Processing file 1951/4224\n",
      "Processing file 2001/4224\n",
      "Processing file 2051/4224\n",
      "Processing file 2101/4224\n",
      "Processing file 2151/4224\n",
      "Processing file 2201/4224\n",
      "Processing file 2251/4224\n",
      "Processing file 2301/4224\n",
      "Processing file 2351/4224\n",
      "Processing file 2401/4224\n",
      "Processing file 2451/4224\n",
      "Processing file 2501/4224\n",
      "Processing file 2551/4224\n",
      "Processing file 2601/4224\n",
      "Processing file 2651/4224\n",
      "Processing file 2701/4224\n",
      "Processing file 2751/4224\n",
      "Processing file 2801/4224\n",
      "Processing file 2851/4224\n",
      "Processing file 2901/4224\n",
      "Processing file 2951/4224\n",
      "Processing file 3001/4224\n",
      "Processing file 3051/4224\n",
      "Processing file 3101/4224\n",
      "Processing file 3151/4224\n",
      "Processing file 3201/4224\n",
      "Processing file 3251/4224\n",
      "Processing file 3301/4224\n",
      "Processing file 3351/4224\n",
      "Processing file 3401/4224\n",
      "Processing file 3451/4224\n",
      "Processing file 3501/4224\n",
      "Processing file 3551/4224\n",
      "Processing file 3601/4224\n",
      "Processing file 3651/4224\n",
      "Processing file 3701/4224\n",
      "Processing file 3751/4224\n",
      "Processing file 3801/4224\n",
      "Processing file 3851/4224\n",
      "Processing file 3901/4224\n",
      "Processing file 3951/4224\n",
      "Processing file 4001/4224\n",
      "Processing file 4051/4224\n",
      "Processing file 4101/4224\n",
      "Processing file 4151/4224\n",
      "Processing file 4201/4224\n",
      "Dataset loaded: 4224 samples\n",
      "Feature shape: (4224, 33)\n",
      "Spectrogram shape: (4224, 128, 94)\n",
      "\n",
      "=== TRAINING CLASSICAL MODELS ===\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8142\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.7030\n",
      "\n",
      "=== TRAINING DEEP LEARNING MODELS ===\n",
      "Training CNN model...\n",
      "Epoch 1/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 228ms/step - accuracy: 0.2290 - loss: 4.8365 - val_accuracy: 0.1586 - val_loss: 2.2055 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 238ms/step - accuracy: 0.4292 - loss: 1.4999 - val_accuracy: 0.5692 - val_loss: 1.4288 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 237ms/step - accuracy: 0.5114 - loss: 1.2528 - val_accuracy: 0.5822 - val_loss: 1.2435 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 253ms/step - accuracy: 0.5498 - loss: 1.1811 - val_accuracy: 0.6722 - val_loss: 1.0461 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 236ms/step - accuracy: 0.5731 - loss: 1.1531 - val_accuracy: 0.6284 - val_loss: 1.0615 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 238ms/step - accuracy: 0.5964 - loss: 1.0968 - val_accuracy: 0.7077 - val_loss: 0.8571 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 240ms/step - accuracy: 0.6044 - loss: 1.0818 - val_accuracy: 0.7006 - val_loss: 0.8399 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 239ms/step - accuracy: 0.5999 - loss: 1.0853 - val_accuracy: 0.6876 - val_loss: 0.9425 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 236ms/step - accuracy: 0.5870 - loss: 1.1003 - val_accuracy: 0.7385 - val_loss: 0.7739 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 237ms/step - accuracy: 0.6331 - loss: 1.0006 - val_accuracy: 0.7089 - val_loss: 0.8940 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 241ms/step - accuracy: 0.6228 - loss: 1.0181 - val_accuracy: 0.7325 - val_loss: 0.7491 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 238ms/step - accuracy: 0.6382 - loss: 0.9667 - val_accuracy: 0.7538 - val_loss: 0.7913 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 241ms/step - accuracy: 0.6349 - loss: 0.9604 - val_accuracy: 0.7349 - val_loss: 0.8098 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 246ms/step - accuracy: 0.6596 - loss: 0.9449 - val_accuracy: 0.7692 - val_loss: 0.6997 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.6633 - loss: 0.9298 - val_accuracy: 0.7527 - val_loss: 0.6525 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 241ms/step - accuracy: 0.6775 - loss: 0.8460 - val_accuracy: 0.6604 - val_loss: 0.8838 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.6779 - loss: 0.8258 - val_accuracy: 0.7645 - val_loss: 0.6708 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 247ms/step - accuracy: 0.7006 - loss: 0.8057 - val_accuracy: 0.8166 - val_loss: 0.5458 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 246ms/step - accuracy: 0.7008 - loss: 0.7910 - val_accuracy: 0.7870 - val_loss: 0.6325 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 245ms/step - accuracy: 0.7048 - loss: 0.7779 - val_accuracy: 0.8107 - val_loss: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 237ms/step - accuracy: 0.7030 - loss: 0.7640 - val_accuracy: 0.8012 - val_loss: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 233ms/step - accuracy: 0.7305 - loss: 0.7366 - val_accuracy: 0.7680 - val_loss: 0.6587 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 233ms/step - accuracy: 0.7220 - loss: 0.7798 - val_accuracy: 0.8260 - val_loss: 0.5243 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 243ms/step - accuracy: 0.7196 - loss: 0.7288 - val_accuracy: 0.6249 - val_loss: 2.6147 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 244ms/step - accuracy: 0.7253 - loss: 0.7132 - val_accuracy: 0.7988 - val_loss: 0.5893 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.7460 - loss: 0.6930 - val_accuracy: 0.8166 - val_loss: 0.5397 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 233ms/step - accuracy: 0.7361 - loss: 0.7186 - val_accuracy: 0.8308 - val_loss: 0.4968 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 238ms/step - accuracy: 0.7513 - loss: 0.6610 - val_accuracy: 0.8379 - val_loss: 0.4795 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 239ms/step - accuracy: 0.7523 - loss: 0.6565 - val_accuracy: 0.8249 - val_loss: 0.4947 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 237ms/step - accuracy: 0.7628 - loss: 0.6463 - val_accuracy: 0.8379 - val_loss: 0.4881 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 236ms/step - accuracy: 0.7725 - loss: 0.6058 - val_accuracy: 0.8024 - val_loss: 0.6239 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m 47/106\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - accuracy: 0.7676 - loss: 0.6219"
     ]
    }
   ],
   "source": [
    "# Speech Emotion Recognition System\n",
    "# Complete implementation with preprocessing, feature extraction, model training, and deployment\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AudioPreprocessor:\n",
    "    \"\"\"Class for audio preprocessing operations\"\"\"\n",
    "    \n",
    "    def __init__(self, target_sr=16000, duration=3.0):\n",
    "        self.target_sr = target_sr\n",
    "        self.duration = duration\n",
    "        self.target_length = int(target_sr * duration)\n",
    "    \n",
    "    def load_and_preprocess(self, file_path):\n",
    "        \"\"\"Load and preprocess audio file\"\"\"\n",
    "        try:\n",
    "            # Load audio file\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            \n",
    "            # Convert to mono if stereo\n",
    "            if len(audio.shape) > 1:\n",
    "                audio = librosa.to_mono(audio)\n",
    "            \n",
    "            # Resample to target sample rate\n",
    "            if sr != self.target_sr:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=self.target_sr)\n",
    "            \n",
    "            # Trim silence\n",
    "            audio, _ = librosa.effects.trim(audio, top_db=20)\n",
    "            \n",
    "            # Normalize audio\n",
    "            audio = librosa.util.normalize(audio)\n",
    "            \n",
    "            # Pad or trim to fixed length\n",
    "            if len(audio) > self.target_length:\n",
    "                audio = audio[:self.target_length]\n",
    "            else:\n",
    "                audio = np.pad(audio, (0, self.target_length - len(audio)), mode='constant')\n",
    "            \n",
    "            return audio\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Class for extracting audio features\"\"\"\n",
    "    \n",
    "    def __init__(self, sr=16000, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "    \n",
    "    def extract_mfcc(self, audio):\n",
    "        \"\"\"Extract MFCC features\"\"\"\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=self.sr, n_mfcc=self.n_mfcc,\n",
    "                                   n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        return np.mean(mfcc.T, axis=0)\n",
    "    \n",
    "    def extract_mel_spectrogram(self, audio):\n",
    "        \"\"\"Extract Mel-spectrogram\"\"\"\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=self.sr,\n",
    "                                                 n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                                                 n_mels=128)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        return mel_spec_db\n",
    "    \n",
    "    def extract_chroma(self, audio):\n",
    "        \"\"\"Extract Chroma features\"\"\"\n",
    "        try:\n",
    "            # Try newer librosa version first\n",
    "            chroma = librosa.feature.chroma_stft(y=audio, sr=self.sr,\n",
    "                                               n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                # Try older librosa version\n",
    "                chroma = librosa.feature.chroma(y=audio, sr=self.sr,\n",
    "                                               n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "            except AttributeError:\n",
    "                # Fallback: compute chroma manually\n",
    "                stft = librosa.stft(audio, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "                chroma = librosa.feature.chroma_stft(S=np.abs(stft), sr=self.sr)\n",
    "        \n",
    "        return np.mean(chroma.T, axis=0)\n",
    "    \n",
    "    def extract_spectral_features(self, audio):\n",
    "        \"\"\"Extract spectral features\"\"\"\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=self.sr)[0]\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=self.sr)[0]\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=self.sr)[0]\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean(spectral_centroids),\n",
    "            np.std(spectral_centroids),\n",
    "            np.mean(spectral_rolloff),\n",
    "            np.std(spectral_rolloff),\n",
    "            np.mean(spectral_bandwidth),\n",
    "            np.std(spectral_bandwidth),\n",
    "            np.mean(zero_crossing_rate),\n",
    "            np.std(zero_crossing_rate)\n",
    "        ])\n",
    "    \n",
    "    def extract_all_features(self, audio):\n",
    "        \"\"\"Extract all features and combine them\"\"\"\n",
    "        mfcc = self.extract_mfcc(audio)\n",
    "        chroma = self.extract_chroma(audio)\n",
    "        spectral = self.extract_spectral_features(audio)\n",
    "        \n",
    "        # Combine all features\n",
    "        features = np.concatenate([mfcc, chroma, spectral])\n",
    "        return features\n",
    "\n",
    "class DatasetLoader:\n",
    "    \"\"\"Class for loading and organizing the dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.preprocessor = AudioPreprocessor()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load dataset from folder structure\"\"\"\n",
    "        emotions = ['sad', 'pleasant_surprise', 'neutral', 'happy', 'fear', 'disgust', 'angry']\n",
    "        \n",
    "        audio_files = []\n",
    "        labels = []\n",
    "        \n",
    "        for emotion in emotions:\n",
    "            emotion_path = os.path.join(self.data_path, emotion)\n",
    "            if os.path.exists(emotion_path):\n",
    "                for file in os.listdir(emotion_path):\n",
    "                    if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "                        audio_files.append(os.path.join(emotion_path, file))\n",
    "                        labels.append(emotion)\n",
    "        \n",
    "        return audio_files, labels\n",
    "    \n",
    "    def process_dataset(self):\n",
    "        \"\"\"Process entire dataset and extract features\"\"\"\n",
    "        audio_files, labels = self.load_dataset()\n",
    "        \n",
    "        print(f\"Found {len(audio_files)} audio files\")\n",
    "        print(f\"Emotions: {set(labels)}\")\n",
    "        \n",
    "        # Extract features\n",
    "        features_list = []\n",
    "        spectrograms = []\n",
    "        processed_labels = []\n",
    "        \n",
    "        for i, (file_path, label) in enumerate(zip(audio_files, labels)):\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Processing file {i+1}/{len(audio_files)}\")\n",
    "            \n",
    "            # Preprocess audio\n",
    "            audio = self.preprocessor.load_and_preprocess(file_path)\n",
    "            \n",
    "            if audio is not None:\n",
    "                # Extract features for classical ML\n",
    "                features = self.feature_extractor.extract_all_features(audio)\n",
    "                features_list.append(features)\n",
    "                \n",
    "                # Extract mel-spectrogram for deep learning\n",
    "                mel_spec = self.feature_extractor.extract_mel_spectrogram(audio)\n",
    "                spectrograms.append(mel_spec)\n",
    "                \n",
    "                processed_labels.append(label)\n",
    "        \n",
    "        return np.array(features_list), np.array(spectrograms), np.array(processed_labels)\n",
    "\n",
    "class EmotionClassifier:\n",
    "    \"\"\"Main class for emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.classical_models = {}\n",
    "        self.deep_models = {}\n",
    "        \n",
    "    def prepare_data(self, features, spectrograms, labels):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        # Encode labels\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Split data\n",
    "        (X_features_train, X_features_test, \n",
    "         X_spec_train, X_spec_test, \n",
    "         y_train, y_test) = train_test_split(\n",
    "            features, spectrograms, encoded_labels, \n",
    "            test_size=0.2, random_state=42, stratify=encoded_labels\n",
    "        )\n",
    "        \n",
    "        # Scale features for classical ML\n",
    "        X_features_train_scaled = self.scaler.fit_transform(X_features_train)\n",
    "        X_features_test_scaled = self.scaler.transform(X_features_test)\n",
    "        \n",
    "        # Prepare spectrograms for deep learning\n",
    "        X_spec_train = X_spec_train.reshape(X_spec_train.shape[0], X_spec_train.shape[1], X_spec_train.shape[2], 1)\n",
    "        X_spec_test = X_spec_test.reshape(X_spec_test.shape[0], X_spec_test.shape[1], X_spec_test.shape[2], 1)\n",
    "        \n",
    "        # Convert labels to categorical for deep learning\n",
    "        y_train_cat = to_categorical(y_train)\n",
    "        y_test_cat = to_categorical(y_test)\n",
    "        \n",
    "        return (X_features_train_scaled, X_features_test_scaled, \n",
    "                X_spec_train, X_spec_test, \n",
    "                y_train, y_test, y_train_cat, y_test_cat)\n",
    "    \n",
    "    def train_classical_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train classical ML models\"\"\"\n",
    "        models = {\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "            # Save model\n",
    "            joblib.dump(model, f'{name.lower().replace(\" \", \"_\")}_model.pkl')\n",
    "        \n",
    "        self.classical_models = results\n",
    "        return results\n",
    "    \n",
    "    def create_cnn_model(self, input_shape, num_classes):\n",
    "        \"\"\"Create CNN model for spectrogram classification\"\"\"\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Flatten(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_deep_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train deep learning models\"\"\"\n",
    "        num_classes = len(np.unique(y_train.argmax(axis=1)))\n",
    "        input_shape = X_train.shape[1:]\n",
    "        \n",
    "        # Create and train CNN\n",
    "        print(\"Training CNN model...\")\n",
    "        cnn_model = self.create_cnn_model(input_shape, num_classes)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=0.0001\n",
    "        )\n",
    "        \n",
    "        # Train CNN\n",
    "        history = cnn_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate CNN\n",
    "        cnn_pred = cnn_model.predict(X_test)\n",
    "        cnn_accuracy = accuracy_score(y_test.argmax(axis=1), cnn_pred.argmax(axis=1))\n",
    "        \n",
    "        print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "        \n",
    "        # Save model\n",
    "        cnn_model.save('cnn_emotion_model.h5')\n",
    "        \n",
    "        self.deep_models['CNN'] = {\n",
    "            'model': cnn_model,\n",
    "            'accuracy': cnn_accuracy,\n",
    "            'history': history,\n",
    "            'predictions': cnn_pred.argmax(axis=1)\n",
    "        }\n",
    "        \n",
    "        return self.deep_models\n",
    "    \n",
    "    def evaluate_models(self, y_true, predictions_dict):\n",
    "        \"\"\"Evaluate and compare all models\"\"\"\n",
    "        print(\"\\n=== MODEL EVALUATION ===\")\n",
    "        \n",
    "        for model_name, pred_data in predictions_dict.items():\n",
    "            if isinstance(pred_data, dict):\n",
    "                predictions = pred_data['predictions']\n",
    "                accuracy = pred_data['accuracy']\n",
    "            else:\n",
    "                predictions = pred_data\n",
    "                accuracy = accuracy_score(y_true, predictions)\n",
    "            \n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_true, predictions, \n",
    "                                      target_names=self.label_encoder.classes_))\n",
    "    \n",
    "    def plot_confusion_matrices(self, y_true, predictions_dict):\n",
    "        \"\"\"Plot confusion matrices for all models\"\"\"\n",
    "        n_models = len(predictions_dict)\n",
    "        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
    "        if n_models == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, (model_name, pred_data) in enumerate(predictions_dict.items()):\n",
    "            if isinstance(pred_data, dict):\n",
    "                predictions = pred_data['predictions']\n",
    "            else:\n",
    "                predictions = pred_data\n",
    "            \n",
    "            cm = confusion_matrix(y_true, predictions)\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                       xticklabels=self.label_encoder.classes_,\n",
    "                       yticklabels=self.label_encoder.classes_,\n",
    "                       ax=axes[idx])\n",
    "            axes[idx].set_title(f'{model_name} Confusion Matrix')\n",
    "            axes[idx].set_xlabel('Predicted')\n",
    "            axes[idx].set_ylabel('Actual')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_feature_importance(self):\n",
    "        \"\"\"Plot feature importance for Random Forest\"\"\"\n",
    "        if 'Random Forest' in self.classical_models:\n",
    "            rf_model = self.classical_models['Random Forest']['model']\n",
    "            \n",
    "            # Create feature names\n",
    "            feature_names = (\n",
    "                [f'MFCC_{i}' for i in range(13)] + \n",
    "                [f'Chroma_{i}' for i in range(12)] + \n",
    "                ['Spectral_Centroid_Mean', 'Spectral_Centroid_Std',\n",
    "                 'Spectral_Rolloff_Mean', 'Spectral_Rolloff_Std',\n",
    "                 'Spectral_Bandwidth_Mean', 'Spectral_Bandwidth_Std',\n",
    "                 'ZCR_Mean', 'ZCR_Std']\n",
    "            )\n",
    "            \n",
    "            importances = rf_model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:20]  # Top 20 features\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title('Feature Importance (Random Forest)')\n",
    "            plt.bar(range(20), importances[indices])\n",
    "            plt.xticks(range(20), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Initialize the emotion classifier\n",
    "    classifier = EmotionClassifier()\n",
    "    \n",
    "    # Load and process dataset\n",
    "    dataset_loader = DatasetLoader('data')  # Update with your data path\n",
    "    \n",
    "    print(\"Loading and processing dataset...\")\n",
    "    features, spectrograms, labels = dataset_loader.process_dataset()\n",
    "    \n",
    "    print(f\"Dataset loaded: {len(features)} samples\")\n",
    "    print(f\"Feature shape: {features.shape}\")\n",
    "    print(f\"Spectrogram shape: {spectrograms.shape}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    (X_features_train, X_features_test, \n",
    "     X_spec_train, X_spec_test, \n",
    "     y_train, y_test, \n",
    "     y_train_cat, y_test_cat) = classifier.prepare_data(features, spectrograms, labels)\n",
    "    \n",
    "    # Train classical models\n",
    "    print(\"\\n=== TRAINING CLASSICAL MODELS ===\")\n",
    "    classical_results = classifier.train_classical_models(\n",
    "        X_features_train, y_train, X_features_test, y_test\n",
    "    )\n",
    "    \n",
    "    # Train deep learning models\n",
    "    print(\"\\n=== TRAINING DEEP LEARNING MODELS ===\")\n",
    "    deep_results = classifier.train_deep_models(\n",
    "        X_spec_train, y_train_cat, X_spec_test, y_test_cat\n",
    "    )\n",
    "    \n",
    "    # Combine all predictions for evaluation\n",
    "    all_predictions = {}\n",
    "    all_predictions.update(classical_results)\n",
    "    \n",
    "    # Convert deep learning predictions to match classical format\n",
    "    for name, result in deep_results.items():\n",
    "        all_predictions[name] = {\n",
    "            'predictions': result['predictions'],\n",
    "            'accuracy': result['accuracy']\n",
    "        }\n",
    "    \n",
    "    # Evaluate models\n",
    "    classifier.evaluate_models(y_test, all_predictions)\n",
    "    \n",
    "    # Plot confusion matrices\n",
    "    classifier.plot_confusion_matrices(y_test, all_predictions)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    classifier.plot_feature_importance()\n",
    "    \n",
    "    # Save label encoder and scaler\n",
    "    joblib.dump(classifier.label_encoder, 'label_encoder.pkl')\n",
    "    joblib.dump(classifier.scaler, 'scaler.pkl')\n",
    "    \n",
    "    print(\"\\nTraining completed! Models and artifacts saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63470761-b64d-4a9b-a37b-cb73f3808334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
